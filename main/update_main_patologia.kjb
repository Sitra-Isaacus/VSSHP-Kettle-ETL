<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>update_main_patologia</name>
  <description />
  <extended_description />
  <job_version />
  <job_status>0</job_status>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2016/05/18 12:45:30.728</created_date>
  <modified_user>-</modified_user>
  <modified_date>2016/05/18 12:45:30.728</modified_date>
  <parameters>
    <parameter>
      <name>config_dir</name>
      <default_value>${Internal.Job.Filename.Directory}</default_value>
      <description />
    </parameter>
    <parameter>
      <name>config_filename</name>
      <default_value>patologia_config.properties</default_value>
      <description />
    </parameter>
  </parameters>
  <connection>
    <name>PostgreSQL parametrized 1</name>
    <server>${host1}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${database1}</database>
    <port>${port1}</port>
    <username>${user1}</username>
    
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${port1}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection />
    <schema />
    <table />
    <size_limit_lines />
    <interval />
    <timeout_days />
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection />
    <schema />
    <table />
    <timeout_days />
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection />
    <schema />
    <table />
    <timeout_days />
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file />
  <entries>
    <entry>
      <name>START</name>
      <description />
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>32</xloc>
      <yloc>32</yloc>
    </entry>
    <entry>
      <name>Insert new patients</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/insert_new_patients.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>592</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>Insert or update potilas_asia's</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/insert_patologia_potilas_asia.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>816</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>Insert patologia elin-diagnoosi</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/insert_patologia_elin_diagnoosi.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>288</yloc>
    </entry>
    <entry>
      <name>Insert patologia tutkimus</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/insert_patologia_tutkimus.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>736</xloc>
      <yloc>288</yloc>
    </entry>
    <entry>
      <name>create table zz_sample_order_answer</name>
      <description />
      <type>SQL</type>
      <sql>-- ##########################
-- Create a joined version of the tables qpatisample, qpatiorder and qpatianswer


-- drop if exists
drop table if exists ${source_schema}.zz_sample_order_answer;

-- create table
create unlogged table ${source_schema}.zz_sample_order_answer as 
select s.qpatisample_id,
-- replace null exporttimes with a date that is before any actual exporttimes (automated export started in Feb 2016)
coalesce(s.exporttime, '2016-01-01 00:00:01') as exporttime,
s.patientid,
s.samplenumberexternal, s.xml_filename, s.io,
o.qpatiorder_id, o.ordernumber, a.qpatianswer_id,
acked, ackingsaved, age, anamnesis, anamnesistablename, answercopy, answerdelaydays, answerdelayminutes, answernumber,
arrived, arrivedin, arrivingsaved, biobankprotocol, 
clinicalextrainfo, concerned, controlcodes, deathdate, dictated, 
dictationwriter, disposingallowed, disposingdate, donebyunit, 
donebyunithl7id, donebyunitsamplenumber, extrawageincluded, hl7id, 
hurry, internalid, isolation, laboratory, language, maintype, 
massacked, newanswerbefore, newanswerbeforedate, nextsampletosameexaminer, 
nohl7sending,
-- cast to int when possible (only a few exceptions)
case when numberofblocks ~ '^\d+$' then cast(numberofblocks as integer)
else cast(null as integer) end as numberofblocks,
case when numberofslides ~ '^\d+$' then cast(numberofslides as integer)
else cast(null as integer) end as numberofslides,
-- numberofbottles cannot be cast to int, is mainly varchar content
numberofbottles,
onstartassistant, onstartdate, onstartperson, orderid, othercomments, 
papaclass, patientadministrationid, payablesaccountnumber, 
payclass, payer, phonedanswer, price, printmacroscopystatement, 
printmacroscopytable, project, protected, quickack, readybefore, 
readyforack, receiver, returned, reviewer, reviewingassigned, 
reviewingdirected, reviewingready, reviewingtablename,
sampletaken,sampletype,savingtime,
sender, sendingdoctor, sent, serialsample, 
splitdate, splitexaminer, splitteam, splitteamdate, statement, 
statementnote, sytologyassistantsnote, sytologyassistantspapaclass, 
sytologyprevcheckdate, sytologyprevchecktablename, sytologyprevchecktablename_bpid, 
transcribed, underrepair, qpatiansweruser, versionnumber, whatandwhere, t.vastaus_kuuluu_vsshp

from ${source_schema}.qpatisample as s
inner join ${source_schema}.zz_samples as zz on s.qpatisample_id = zz.qpatisample_id -- only the newest version of each sample

left outer join ${source_schema}.qpatiorder as o
on s.qpatisample_id = o.qpatisample_id

left outer join ${source_schema}.qpatianswer as a
on a.qpatiorder_id = o.qpatiorder_id

left outer join ${map_schema}.qpati_tilaaja as t
on case when a.receiver is null or a.receiver = '' then a.sender else a.receiver end  = t.tilaaja_koko_nimi

where (
a.acked is not null
or --  old samples from a time when acking was not obligatory
extract(year from a.arrived) &lt; 1993 and substring(s.samplenumberexternal,1,1) in ('A', 'V', 'D')
)
;

</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>F</sendOneStatement>
      <connection>PostgreSQL parametrized 1</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>640</xloc>
      <yloc>32</yloc>
    </entry>
    <entry>
      <name>Insert patologia_vastaus</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/insert_patologia_vastaus.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>240</xloc>
      <yloc>288</yloc>
    </entry>
    <entry>
      <name>Initialize variables for code ids</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/patol_init_variables.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>368</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>Update CDC start time</name>
      <description />
      <type>SQL</type>
      <sql>-- mark the beginning of the cdc process from files to stage

update ${target_schema}.cdc_time
set current_load = now()
where process_name = 'patologia';</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>F</sendOneStatement>
      <connection>PostgreSQL parametrized 1</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>32</yloc>
    </entry>
    <entry>
      <name>Mark CDC as finished</name>
      <description />
      <type>SQL</type>
      <sql>
-- mark the current load as finished

update ${target_schema}.cdc_time
set last_load = current_load, current_load = null
where process_name = 'patologia';
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>F</sendOneStatement>
      <connection>PostgreSQL parametrized 1</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>944</xloc>
      <yloc>400</yloc>
    </entry>
    <entry>
      <name>Delete obsolete samples from main patologia</name>
      <description />
      <type>SQL</type>
      <sql>
-- data that is in zz_sample_order_answer will replace the data for those sampleNumberExternals in the main patologia tables


-- delete all statement table data for answers that have been replaced with newer versions
delete from 
${target_schema}.patologia_taulukkoarvo as t
using ${target_schema}.patologia_vastaus as v
inner join ${source_schema}.zz_sample_order_answer as z on v.naytenumero = z.samplenumberexternal
where t.patologia_vastaus_id = v.patologia_vastaus_id;


-- delete all examination data for answers that have been replaced with newer versions
delete from 
${target_schema}.patologia_tutkimus as t
using ${target_schema}.patologia_vastaus as v
inner join ${source_schema}.zz_sample_order_answer as z on v.naytenumero = z.samplenumberexternal
where t.patologia_vastaus_id = v.patologia_vastaus_id;


-- delete all diagnosis data for answers that have been replaced with newer versions
delete from 
${target_schema}.patologia_elin_diagnoosi as t
using ${target_schema}.patologia_vastaus as v
inner join ${source_schema}.zz_sample_order_answer as z on v.naytenumero = z.samplenumberexternal
where t.patologia_vastaus_id = v.patologia_vastaus_id;

-- delete all answers that have been replaced with newer versions
delete from 
${target_schema}.patologia_vastaus as v
using ${source_schema}.zz_sample_order_answer as z
where v.naytenumero = z.samplenumberexternal;

 

</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>T</sendOneStatement>
      <connection>PostgreSQL parametrized 1</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1088</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>Insert statement tables</name>
      <description />
      <type>JOB</type>
      <specification_method>filename</specification_method>
      <job_object_id />
      <filename>${Internal.Job.Filename.Directory}/transformations/patologia/insert_statement_tables.kjb</filename>
      <jobname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name />
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>944</xloc>
      <yloc>288</yloc>
    </entry>
    <entry>
      <name>Find newest version of each new sample</name>
      <description />
      <type>SQL</type>
      <sql>----------------------------------------------------
-- create list of unique sample versions for those samples that are new
-- (to help compare which sample is a newer version of which other sample)

drop table if exists ${source_schema}.zz_samples;

create unlogged table ${source_schema}.zz_samples as
select distinct qpatisample_id, samplenumberexternal, io, coalesce(s.exporttime, '2016-01-01 00:00:01') as exporttime
from ${source_schema}.qpatisample as s
inner join ${target_schema}.cdc_time as c on c.process_name = 'patologia'
where s.paivityshetki_stage > c.last_load

;


-----------------------------------------------------------------------
-- delete samples that have a newer XML dataset, based on ExportTime

delete from ${source_schema}.zz_samples as s1
using ${source_schema}.zz_samples as s2
where s1.samplenumberexternal = s2.samplenumberexternal
and s1.qpatisample_id != s2.qpatisample_id
and s2.exporttime > s1.exporttime;


----------------------------------------------------------------------------------
-- if there are duplicate SampleNumberExternal's that have the same exporttime,
-- the one with the smaller qpatisample_id is deleted (= i.e. semi-randomly)

delete from ${source_schema}.zz_samples as s1
using ${source_schema}.zz_samples as s2
where s1.io &lt; s2.io
and s1.exporttime = s2.exporttime
and s1.samplenumberexternal = s2.samplenumberexternal;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>F</sendOneStatement>
      <connection>PostgreSQL parametrized 1</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>368</xloc>
      <yloc>32</yloc>
    </entry>
    <entry>
      <name>Refresh materialized views</name>
      <description />
      <type>SQL</type>
      <sql>

update ${target_schema}.cdc_time set current_load = now() where process_name = 'mv_patologia_vastaus_vsshp';

refresh materialized view ${target_schema}.mv_patologia_vastaus_vsshp;

update ${target_schema}.cdc_time set last_load = current_load, current_load = null where process_name = 'mv_patologia_vastaus_vsshp';


-------------------------

update ${target_schema}.cdc_time set current_load = now() where process_name = 'mv_patologia_elin_diagnoosi_vsshp';

refresh materialized view ${target_schema}.mv_patologia_elin_diagnoosi_vsshp;

update ${target_schema}.cdc_time set last_load = current_load, current_load = null where process_name = 'mv_patologia_elin_diagnoosi_vsshp';

--------------------------

update ${target_schema}.cdc_time set current_load = now() where process_name = 'mv_patologia_tutkimus_vsshp';

refresh materialized view ${target_schema}.mv_patologia_tutkimus_vsshp;

update ${target_schema}.cdc_time set last_load = current_load, current_load = null where process_name = 'mv_patologia_tutkimus_vsshp';

---------------------------------

update ${target_schema}.cdc_time set current_load = now() where process_name = 'mv_patologia_taulukkoarvo_vsshp';

refresh materialized view ${target_schema}.mv_patologia_taulukkoarvo_vsshp;

update ${target_schema}.cdc_time set last_load = current_load, current_load = null where process_name = 'mv_patologia_taulukkoarvo_vsshp';
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>F</sendOneStatement>
      <connection>PostgreSQL parametrized 1</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1152</xloc>
      <yloc>400</yloc>
    </entry>
    <entry>
      <name>Read config</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${user.home}/ETL/general_transformations/set_variables_from_properties_file.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>32</xloc>
      <yloc>208</yloc>
    </entry>
    <entry>
      <name>Read passwords</name>
      <description />
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${user.home}/ETL/general_transformations/set_passwords_from_properties_file.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>208</yloc>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>Insert patologia elin-diagnoosi</from>
      <to>Insert patologia tutkimus</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Insert patologia_vastaus</from>
      <to>Insert patologia elin-diagnoosi</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Insert new patients</from>
      <to>Insert or update potilas_asia's</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Initialize variables for code ids</from>
      <to>Insert new patients</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Insert or update potilas_asia's</from>
      <to>Delete obsolete samples from main patologia</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Insert patologia tutkimus</from>
      <to>Insert statement tables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Insert statement tables</from>
      <to>Mark CDC as finished</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Update CDC start time</from>
      <to>Find newest version of each new sample</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Find newest version of each new sample</from>
      <to>create table zz_sample_order_answer</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>create table zz_sample_order_answer</from>
      <to>Initialize variables for code ids</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Delete obsolete samples from main patologia</from>
      <to>Insert patologia_vastaus</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Mark CDC as finished</from>
      <to>Refresh materialized views</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>Read config</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Read config</from>
      <to>Read passwords</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Read passwords</from>
      <to>Update CDC start time</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>deletes rows
that will be replaced with newer information</note>
      <xloc>1152</xloc>
      <yloc>240</yloc>
      <width>299</width>
      <heigth>44</heigth>
      <fontname />
      <fontsize>-1</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>pick samples from stage that need to be inserted or updated into target_schema.
Include information on whether is VSSHP data or not (ulkopuolinen(bit) is 1 or 0).</note>
      <xloc>736</xloc>
      <yloc>16</yloc>
      <width>539</width>
      <heigth>44</heigth>
      <fontname>Sans</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>only inserts, no updates,
because old versions were deleted first</note>
      <xloc>336</xloc>
      <yloc>368</yloc>
      <width>265</width>
      <heigth>44</heigth>
      <fontname />
      <fontsize>-1</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Delete samples that have a newer version.
Takes about 12 min for full data set (originally from ~1,2M XML files)</note>
      <xloc>976</xloc>
      <yloc>80</yloc>
      <width>459</width>
      <heigth>44</heigth>
      <fontname>Sans</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
      <attribute>
        <key>Pentaho local</key>
        <value>{"children":[{"children":[],"id":"server","value":null},{"children":[],"id":"clustered","value":"N"},{"children":[],"id":"name","value":"Pentaho local"},{"children":[],"id":"description","value":null},{"children":[],"id":"readOnly","value":"Y"},{"children":[],"id":"sendResources","value":"N"},{"children":[],"id":"logRemoteExecutionLocally","value":"N"},{"children":[],"id":"remote","value":"N"},{"children":[],"id":"local","value":"Y"},{"children":[],"id":"showTransformations","value":"N"}],"id":"Pentaho local","value":null,"name":"Pentaho local","owner":null,"ownerPermissionsList":[]}</value>
      </attribute>
    </group>
  </attributes>
</job>
